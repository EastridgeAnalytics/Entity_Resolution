{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Resolution Demo Notebook\n",
    "\n",
    "This notebook was created to showcase how Neo4j can help to indentfy and resolve duplication cause by near-similarities in your database. \n",
    "\n",
    "There are a few pre-requisites to take care of before we get started. \n",
    "\n",
    "\n",
    "## 0. Pre-requisites\n",
    "\n",
    "\n",
    "### Python Packages\n",
    "Be sure you have installed the following python packages\n",
    "\n",
    "`pip3 install faker neo4j`\n",
    "\n",
    "or \n",
    "\n",
    "`conda install faker conda-forge::neo4j-python-driver`\n",
    "\n",
    "If conda isntall is not working, please refer to [anaconda.org](https://anaconda.org/conda-forge/neo4j-python-driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import logging\n",
    "from typing import Optional, Dict, List, Any\n",
    "from faker import Faker\n",
    "from neo4j import GraphDatabase, Driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neo4j DataBase\n",
    "\n",
    "Before starting this demo, make sure to create a new database and update the URI AND PASSWORD DB_NAME below. You may also need to update the USER or DB_NAM if those are different for your DB instance. \n",
    "\n",
    "We recommend using [Neo4j Desktop](https://neo4j.com/product/#neo4j-desktop) as it allows you to use Graph Data Science Library at no cost.  If you are using Neo4J Desktop, you can find your URI by clicking Details and copying the \"Bolt port\".\n",
    "\n",
    "\n",
    "You will also need to ensure APOC and Graph Data Science are enabled on your instance. If you do not do this, you will receive errors later in the notebook.\n",
    "- [Installing APOC](https://neo4j.com/docs/apoc/current/installation/)\n",
    "- [Installing GDC](https://neo4j.com/docs/graph-data-science/current/installation/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URI = os.getenv(\"NEO4J_URI\", \"bolt://localhost:7687\")\n",
    "USER = os.getenv(\"NEO4J_USER\", \"neo4j\")\n",
    "PASSWORD = os.getenv(\"NEO4J_PASSWORD\", \"password\")\n",
    "DB_NAME = os.getenv(\"NEO4J_DB\", \"neo4j\")\n",
    "BATCH_ID = \"batch1\"\n",
    "TOTAL_NODES = 10000\n",
    "DUPLICATE_PERCENT = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, configure logging and add a helper function (get_driver) is also defined to easily obtain a Neo4j driver instance. This setup is essential to ensure the environment is ready for the subsequent tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Logging Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --- Driver Helper ---\n",
    "def get_driver() -> Driver:\n",
    "    \"\"\"Return a Neo4j driver instance.\"\"\"\n",
    "    return GraphDatabase.driver(URI, auth=(USER, PASSWORD))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create mock data candidates\n",
    "\n",
    "This section defines utility functions that support data generation.\n",
    "\n",
    "- cleanup_previous_batch clears existing candidate data for the current batch.\n",
    "- introduce_small_typo and introduce_phone_variation simulate common data imperfections by introducing slight variations.\n",
    "\n",
    "These functions help create realistic, messy data for testing the entity resolution process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_previous_batch(driver: Driver) -> None:\n",
    "    \"\"\"Removes all Candidate nodes for the current batch.\"\"\"\n",
    "    with driver.session(database=DB_NAME) as session:\n",
    "        session.run(f\"MATCH (c:Candidate {{batchId:'{BATCH_ID}'}}) DETACH DELETE c\")\n",
    "    logger.info(f\"Old Candidate nodes for batch '{BATCH_ID}' removed.\")\n",
    "\n",
    "def introduce_small_typo(original_str: str) -> str:\n",
    "    \"\"\"Introduce a small typo in a string.\"\"\"\n",
    "    if not original_str or len(original_str) < 5:\n",
    "        return original_str\n",
    "    if random.random() < 0.5:\n",
    "        return original_str\n",
    "    s_list = list(original_str)\n",
    "    pos = random.randint(0, len(s_list) - 1)\n",
    "    if random.random() < 0.5:\n",
    "        del s_list[pos]\n",
    "    else:\n",
    "        s_list[pos] = chr(random.randint(ord('a'), ord('z')))\n",
    "    return \"\".join(s_list)\n",
    "\n",
    "def introduce_phone_variation(phone_str: str) -> str:\n",
    "    \"\"\"Slightly modifies a phone number.\"\"\"\n",
    "    if not phone_str:\n",
    "        return phone_str\n",
    "    if random.random() < 0.5:\n",
    "        return phone_str  # Leave unchanged half the time\n",
    "    only_digits = ''.join(filter(str.isdigit, phone_str))\n",
    "    if len(only_digits) > 6:\n",
    "        if random.random() < 0.5:\n",
    "            only_digits = only_digits[:-1]\n",
    "        else:\n",
    "            only_digits = only_digits[:-1] + str(random.randint(0,9))\n",
    "    formatted = only_digits\n",
    "    if len(only_digits) > 3:\n",
    "        formatted = f\"({only_digits[:3]}) {only_digits[3:]}\"\n",
    "    return formatted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we generate a set of candidate nodes using the Faker library, simulating a large dataset with intentional near-duplicates. The data is inserted into Neo4j in batches. This section serves to populate the database with candidate nodes, providing a realistic dataset for testing and development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Connected to Neo4j for mock data generation.\n",
      "INFO: Old Candidate nodes for batch 'batch1' removed.\n",
      "INFO: Inserted batch up to index 0\n",
      "INFO: Inserted batch up to index 1000\n",
      "INFO: Inserted batch up to index 2000\n",
      "INFO: Inserted batch up to index 3000\n",
      "INFO: Inserted batch up to index 4000\n",
      "INFO: Inserted batch up to index 5000\n",
      "INFO: Inserted batch up to index 6000\n",
      "INFO: Inserted batch up to index 7000\n",
      "INFO: Inserted batch up to index 8000\n",
      "INFO: Inserted batch up to index 9000\n",
      "INFO: Inserted batch up to index 10000\n",
      "INFO: Mock data generation complete.\n"
     ]
    }
   ],
   "source": [
    "def create_mock_data(cleanup: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Generates candidate data, injects near-duplicates, and inserts into Neo4j.\n",
    "    \"\"\"\n",
    "    fake = Faker()\n",
    "    Faker.seed(42)\n",
    "    driver = get_driver()\n",
    "    logger.info(\"Connected to Neo4j for mock data generation.\")\n",
    "    \n",
    "    if cleanup:\n",
    "        cleanup_previous_batch(driver)\n",
    "    \n",
    "    candidates: List[Dict[str, Any]] = []\n",
    "    for i in range(TOTAL_NODES):\n",
    "        candidate = {\n",
    "            \"candidateId\": f\"cand_{i}\",\n",
    "            \"batchId\": BATCH_ID,\n",
    "            \"fullName\": fake.name(),\n",
    "            \"email\": fake.email(),\n",
    "            \"phoneNumber\": fake.phone_number(),\n",
    "            \"address\": fake.address().replace(\"\\n\", \", \")\n",
    "        }\n",
    "        candidates.append(candidate)\n",
    "    \n",
    "    # Inject near-duplicates.\n",
    "    num_duplicates = int(TOTAL_NODES * DUPLICATE_PERCENT)\n",
    "    for _ in range(num_duplicates):\n",
    "        original = random.choice(candidates)\n",
    "        duplicate = {\n",
    "            \"candidateId\": f\"dup_{original['candidateId']}_{random.randint(1,100000)}\",\n",
    "            \"batchId\": BATCH_ID,\n",
    "            \"fullName\": introduce_small_typo(original[\"fullName\"]),\n",
    "            \"email\": introduce_small_typo(original[\"email\"]),\n",
    "            \"phoneNumber\": introduce_phone_variation(original[\"phoneNumber\"]),\n",
    "            \"address\": introduce_small_typo(original[\"address\"])\n",
    "        }\n",
    "        candidates.append(duplicate)\n",
    "    \n",
    "    random.shuffle(candidates)\n",
    "    batch_size = 1000\n",
    "    with driver.session(database=DB_NAME) as session:\n",
    "        for i in range(0, len(candidates), batch_size):\n",
    "            batch = candidates[i:i+batch_size]\n",
    "            cypher = \"\"\"\n",
    "            UNWIND $rows AS row\n",
    "            CREATE (c:Candidate {\n",
    "              candidateId: row.candidateId,\n",
    "              batchId: row.batchId,\n",
    "              fullName: row.fullName,\n",
    "              email: row.email,\n",
    "              phoneNumber: row.phoneNumber,\n",
    "              address: row.address\n",
    "            })\n",
    "            \"\"\"\n",
    "            session.run(cypher, parameters={\"rows\": batch})\n",
    "            logger.info(f\"Inserted batch up to index {i}\")\n",
    "    \n",
    "    driver.close()\n",
    "    logger.info(\"Mock data generation complete.\")\n",
    "\n",
    "# Run this cell to generate the mock data:\n",
    "create_mock_data(cleanup=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create \"fraud family\" clusters\n",
    "\n",
    " This section focuses on inserting two specific demo clusters into the database. These clusters (for example, a fraud family and multiple variations of a single individual) serve as controlled test cases. The clusters are inserted using APOC's periodic iteration, which is efficient for batch processing. This controlled data helps in validating the entity resolution logic.\n",
    " \n",
    "Note: apoc library must be installed in Neo4j https://neo4j.com/docs/apoc/current/installation/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Connected to Neo4j for inserting demo clusters.\n",
      "INFO: Inserted one demo cluster.\n",
      "INFO: Inserted one demo cluster.\n",
      "INFO: Demo clusters inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Demo clusters for testing resolution\n",
    "CLUSTER_1_DATA = [\n",
    "    {\n",
    "        \"candidateId\": \"FRAUD_101\",\n",
    "        \"batchId\": BATCH_ID,\n",
    "        \"fullName\": \"Theodore Chadwick\",\n",
    "        \"email\": \"theo.chadwick@gmail.com\",\n",
    "        \"phoneNumber\": \"555-1234\",\n",
    "        \"address\": \"123 Fraud Rd, Chicago\"\n",
    "    },\n",
    "    # ... (other records for cluster 1)\n",
    "]\n",
    "\n",
    "CLUSTER_2_DATA = [\n",
    "    {\n",
    "        \"candidateId\": \"PERSON_201\",\n",
    "        \"batchId\": BATCH_ID,\n",
    "        \"fullName\": \"Jessica Parsons\",\n",
    "        \"email\": \"jessparsons@gmail.com\",\n",
    "        \"phoneNumber\": \"423-502-1235\",\n",
    "        \"address\": \"99 Demo Ln, Springfield\"\n",
    "    },\n",
    "    # ... (other records for cluster 2)\n",
    "]\n",
    "\n",
    "def create_clusters() -> None:\n",
    "    \"\"\"Insert demo clusters into Neo4j.\"\"\"\n",
    "    driver = get_driver()\n",
    "    logger.info(\"Connected to Neo4j for inserting demo clusters.\")\n",
    "    with driver.session(database=DB_NAME) as session:\n",
    "        for cluster_data, batch_size in [(CLUSTER_1_DATA, 5), (CLUSTER_2_DATA, 6)]:\n",
    "            session.run(\n",
    "                \"\"\"\n",
    "                CALL apoc.periodic.iterate(\n",
    "                  'UNWIND $rows AS row RETURN row',\n",
    "                  'CREATE (c:Candidate {\n",
    "                     candidateId: row.candidateId,\n",
    "                     batchId: row.batchId,\n",
    "                     fullName: row.fullName,\n",
    "                     email: row.email,\n",
    "                     phoneNumber: row.phoneNumber,\n",
    "                     address: row.address\n",
    "                   })',\n",
    "                  {batchSize: $batchSize, parallel: false, params: {rows: $rows}}\n",
    "                )\n",
    "                \"\"\",\n",
    "                parameters={\"rows\": cluster_data, \"batchSize\": batch_size},\n",
    "            )\n",
    "            logger.info(\"Inserted one demo cluster.\")\n",
    "    driver.close()\n",
    "    logger.info(\"Demo clusters inserted successfully.\")\n",
    "\n",
    "# Run this cell to insert demo clusters:\n",
    "create_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Normalize the data\n",
    "\n",
    "Data normalization is critical for comparing candidate records reliably. In this section, functions are defined to normalize key properties such as full names, phone numbers, emails, and addresses. The normalize_properties pipeline updates the candidate nodes with standardized values (e.g., normalizedFullName). This consistency is necessary for accurate similarity comparisons later in the process.\n",
    "\n",
    "\n",
    "### First, let's create some helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Connected to Neo4j for property normalization.\n",
      "INFO: Normalized batch up to index 0\n",
      "INFO: Normalized batch up to index 1000\n",
      "INFO: Normalized batch up to index 2000\n",
      "INFO: Normalized batch up to index 3000\n",
      "INFO: Normalized batch up to index 4000\n",
      "INFO: Normalized batch up to index 5000\n",
      "INFO: Normalized batch up to index 6000\n",
      "INFO: Normalized batch up to index 7000\n",
      "INFO: Normalized batch up to index 8000\n",
      "INFO: Normalized batch up to index 9000\n",
      "INFO: Normalized batch up to index 10000\n",
      "INFO: Normalized batch up to index 11000\n",
      "INFO: Property normalization complete.\n"
     ]
    }
   ],
   "source": [
    "def normalize_phone(phone_str: Optional[str]) -> Optional[str]:\n",
    "    \"\"\"Remove non-digit characters from a phone number.\"\"\"\n",
    "    if not phone_str:\n",
    "        return None\n",
    "    digits = re.sub(r'[^0-9]', '', phone_str)\n",
    "    return digits if digits else None\n",
    "\n",
    "def normalize_email(email_str: Optional[str]) -> Optional[str]:\n",
    "    \"\"\"Lowercase and trim email.\"\"\"\n",
    "    if not email_str:\n",
    "        return None\n",
    "    return email_str.strip().lower()\n",
    "\n",
    "def normalize_address(addr_str: Optional[str]) -> Optional[str]:\n",
    "    \"\"\"Simplify and lowercase an address.\"\"\"\n",
    "    if not addr_str:\n",
    "        return None\n",
    "    addr_str = addr_str.lower()\n",
    "    addr_str = re.sub(r'[.,#]', '', addr_str)\n",
    "    addr_str = addr_str.replace(\" street\", \" st\").replace(\" avenue\", \" ave\")\n",
    "    return addr_str.strip()\n",
    "\n",
    "def normalize_name(name_str: Optional[str]) -> Optional[str]:\n",
    "    \"\"\"Lowercase and trim a full name.\"\"\"\n",
    "    if not name_str:\n",
    "        return None\n",
    "    return name_str.strip().lower()\n",
    "\n",
    "def normalize_properties() -> None:\n",
    "    \"\"\"\n",
    "    Normalizes fullName, phone, email, and address for all candidates.\n",
    "    Updates each Candidate node with normalized properties.\n",
    "    \"\"\"\n",
    "    driver = get_driver()\n",
    "    logger.info(\"Connected to Neo4j for property normalization.\")\n",
    "    with driver.session(database=DB_NAME) as session:\n",
    "        fetch_query = f\"\"\"\n",
    "        MATCH (c:Candidate {{batchId:'{BATCH_ID}'}})\n",
    "        RETURN c.candidateId AS candidateId, c.fullName AS fullName,\n",
    "               c.phoneNumber AS phone, c.email AS email, c.address AS address\n",
    "        \"\"\"\n",
    "        result = session.run(fetch_query)\n",
    "        updates: List[Dict[str, Any]] = []\n",
    "        for record in result:\n",
    "            updates.append({\n",
    "                \"candidateId\": record[\"candidateId\"],\n",
    "                \"normalizedFullName\": normalize_name(record[\"fullName\"]),\n",
    "                \"normalizedPhone\": normalize_phone(record[\"phone\"]),\n",
    "                \"normalizedEmail\": normalize_email(record[\"email\"]),\n",
    "                \"normalizedAddress\": normalize_address(record[\"address\"])\n",
    "            })\n",
    "        batch_size = 1000\n",
    "        for i in range(0, len(updates), batch_size):\n",
    "            batch = updates[i:i+batch_size]\n",
    "            update_cypher = \"\"\"\n",
    "            UNWIND $rows AS row\n",
    "            MATCH (c:Candidate {candidateId: row.candidateId})\n",
    "            SET c.normalizedFullName = row.normalizedFullName,\n",
    "                c.normalizedPhone = row.normalizedPhone,\n",
    "                c.normalizedEmail = row.normalizedEmail,\n",
    "                c.normalizedAddress = row.normalizedAddress\n",
    "            \"\"\"\n",
    "            session.run(update_cypher, parameters={\"rows\": batch})\n",
    "            logger.info(f\"Normalized batch up to index {i}\")\n",
    "    driver.close()\n",
    "    logger.info(\"Property normalization complete.\")\n",
    "\n",
    "# Run this cell to normalize properties:\n",
    "normalize_properties()\n",
    "\n",
    "# (Verify in Neo4j Browser with:\n",
    "# MATCH (c:Candidate) RETURN c.fullName, c.normalizedFullName LIMIT 10;)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Calculate Similarity\n",
    "\n",
    "This section sets up candidate matching by first creating indexes on normalized properties and optionally generating blocking keys to reduce comparison overhead. Functions are then defined to create SIMILAR relationships based on full name, email, phone number, and address similarities using measures like Jaro-Winkler and Levenshtein distances. Running these functions links candidate nodes that meet the similarity criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX candidate_candidateId_index IF NOT EXISTS FOR (e:Candidate) ON (e.candidateId)` has no effect.} {description: `RANGE INDEX candidate_candidateId_index FOR (e:Candidate) ON (e.candidateId)` already exists.} {position: None} for query: 'CREATE INDEX candidate_candidateId_index IF NOT EXISTS FOR (c:Candidate) ON (c.candidateId)'\n",
      "INFO: Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX candidate_phone_index IF NOT EXISTS FOR (e:Candidate) ON (e.normalizedPhone)` has no effect.} {description: `RANGE INDEX candidate_phone_index FOR (e:Candidate) ON (e.normalizedPhone)` already exists.} {position: None} for query: 'CREATE INDEX candidate_phone_index IF NOT EXISTS FOR (c:Candidate) ON (c.normalizedPhone)'\n",
      "INFO: Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX candidate_email_index IF NOT EXISTS FOR (e:Candidate) ON (e.normalizedEmail)` has no effect.} {description: `RANGE INDEX candidate_email_index FOR (e:Candidate) ON (e.normalizedEmail)` already exists.} {position: None} for query: 'CREATE INDEX candidate_email_index IF NOT EXISTS FOR (c:Candidate) ON (c.normalizedEmail)'\n",
      "INFO: Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE RANGE INDEX candidate_address_index IF NOT EXISTS FOR (e:Candidate) ON (e.normalizedAddress)` has no effect.} {description: `RANGE INDEX candidate_address_index FOR (e:Candidate) ON (e.normalizedAddress)` already exists.} {position: None} for query: 'CREATE INDEX candidate_address_index IF NOT EXISTS FOR (c:Candidate) ON (c.normalizedAddress)'\n",
      "INFO: Candidate indexes created.\n",
      "INFO: Created SIMILAR relationships by fullName.\n",
      "INFO: Created SIMILAR relationships by email.\n",
      "INFO: Created SIMILAR relationships by phoneNumber.\n",
      "INFO: Created SIMILAR relationships by address.\n"
     ]
    }
   ],
   "source": [
    "def create_candidate_indexes(driver: Driver) -> None:\n",
    "    \"\"\"Creates indexes on candidate properties.\"\"\"\n",
    "    index_queries = [\n",
    "        \"CREATE INDEX candidate_candidateId_index IF NOT EXISTS FOR (c:Candidate) ON (c.candidateId)\",\n",
    "        \"CREATE INDEX candidate_phone_index IF NOT EXISTS FOR (c:Candidate) ON (c.normalizedPhone)\",\n",
    "        \"CREATE INDEX candidate_email_index IF NOT EXISTS FOR (c:Candidate) ON (c.normalizedEmail)\",\n",
    "        \"CREATE INDEX candidate_address_index IF NOT EXISTS FOR (c:Candidate) ON (c.normalizedAddress)\"\n",
    "    ]\n",
    "    with driver.session(database=DB_NAME) as session:\n",
    "        for query in index_queries:\n",
    "            session.run(query)\n",
    "    logger.info(\"Candidate indexes created.\")\n",
    "\n",
    "def create_soundex_blocking(driver: Driver) -> None:\n",
    "    \"\"\"\n",
    "    Creates BlockKey nodes using soundex of normalizedFullName.\n",
    "    Disable if blocking causes issues.\n",
    "    \"\"\"\n",
    "    with driver.session(database=DB_NAME) as session:\n",
    "        session.run(\"MATCH (b:BlockKey) DETACH DELETE b\")\n",
    "        query = f\"\"\"\n",
    "        CALL apoc.periodic.iterate(\n",
    "          'MATCH (c:Candidate {{batchId:\"{BATCH_ID}\"}}) RETURN c',\n",
    "          'WITH c, apoc.text.soundex(c.normalizedFullName) AS sdx\n",
    "           MERGE (bk:BlockKey {{value: sdx}})\n",
    "           MERGE (c)-[:HAS_BLOCK]->(bk)',\n",
    "          {{batchSize:1000, parallel:false}}\n",
    "        )\n",
    "        \"\"\"\n",
    "        session.run(query)\n",
    "    logger.info(\"Soundex blocking applied.\")\n",
    "\n",
    "def create_similarity_by_name(driver: Driver, jaro_threshold: float = 0.15) -> None:\n",
    "    \"\"\"Creates SIMILAR relationships based on full name similarity.\"\"\"\n",
    "    query = f\"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "      \"MATCH (c:Candidate {{batchId:'{BATCH_ID}'}}) RETURN c\",\n",
    "      \"MATCH (c2:Candidate {{batchId:'{BATCH_ID}'}}) \n",
    "       WHERE id(c) < id(c2)\n",
    "       WITH c, c2, apoc.text.jaroWinklerDistance(c.normalizedFullName, c2.normalizedFullName) AS dist\n",
    "       WHERE dist < {jaro_threshold}\n",
    "       CREATE (c)-[:SIMILAR {{\n",
    "         comparedProperty: 'fullName',\n",
    "         similarity: (1.0 - dist)\n",
    "       }}]->(c2)\",\n",
    "      {{batchSize:200, parallel:false}}\n",
    "    )\n",
    "    \"\"\"\n",
    "    with driver.session(database=DB_NAME) as session:\n",
    "        session.run(query)\n",
    "    logger.info(\"Created SIMILAR relationships by fullName.\")\n",
    "\n",
    "def create_similarity_by_email(driver: Driver, similarity_threshold: float = 0.9) -> None:\n",
    "    \"\"\"Creates SIMILAR relationships based on email similarity.\"\"\"\n",
    "    query = f\"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "      \"MATCH (c:Candidate {{batchId:'{BATCH_ID}'}}) WHERE c.normalizedEmail IS NOT NULL RETURN c\",\n",
    "      \"MATCH (c2:Candidate {{batchId:'{BATCH_ID}'}}) \n",
    "       WHERE c2.normalizedEmail IS NOT NULL AND id(c) < id(c2)\n",
    "       WITH c, c2,\n",
    "            apoc.text.levenshteinDistance(c.normalizedEmail, c2.normalizedEmail) AS dist,\n",
    "            CASE WHEN size(c.normalizedEmail) >= size(c2.normalizedEmail) THEN size(c.normalizedEmail) ELSE size(c2.normalizedEmail) END AS maxLen\n",
    "       WITH c, c2, 1.0 - (toFloat(dist)/toFloat(maxLen)) AS sim\n",
    "       WHERE sim >= {similarity_threshold}\n",
    "       CREATE (c)-[:SIMILAR {{\n",
    "         comparedProperty: 'email',\n",
    "         similarity: sim\n",
    "       }}]->(c2)\",\n",
    "      {{batchSize:200, parallel:false}}\n",
    "    )\n",
    "    \"\"\"\n",
    "    with driver.session(database=DB_NAME) as session:\n",
    "        session.run(query)\n",
    "    logger.info(\"Created SIMILAR relationships by email.\")\n",
    "\n",
    "def create_similarity_by_phone(driver: Driver, similarity_threshold: float = 0.9) -> None:\n",
    "    \"\"\"Creates SIMILAR relationships based on phone similarity.\"\"\"\n",
    "    query = f\"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "      \"MATCH (c:Candidate {{batchId:'{BATCH_ID}'}}) WHERE c.normalizedPhone IS NOT NULL RETURN c\",\n",
    "      \"MATCH (c2:Candidate {{batchId:'{BATCH_ID}'}}) \n",
    "       WHERE c2.normalizedPhone IS NOT NULL AND id(c) < id(c2)\n",
    "       WITH c, c2,\n",
    "            apoc.text.levenshteinDistance(c.normalizedPhone, c2.normalizedPhone) AS dist,\n",
    "            CASE WHEN size(c.normalizedPhone) >= size(c2.normalizedPhone) THEN size(c.normalizedPhone) ELSE size(c2.normalizedPhone) END AS maxLen\n",
    "       WITH c, c2, 1.0 - (toFloat(dist)/toFloat(maxLen)) AS sim\n",
    "       WHERE sim >= {similarity_threshold}\n",
    "       CREATE (c)-[:SIMILAR {{\n",
    "         comparedProperty: 'phoneNumber',\n",
    "         similarity: sim\n",
    "       }}]->(c2)\",\n",
    "      {{batchSize:200, parallel:false}}\n",
    "    )\n",
    "    \"\"\"\n",
    "    with driver.session(database=DB_NAME) as session:\n",
    "        session.run(query)\n",
    "    logger.info(\"Created SIMILAR relationships by phoneNumber.\")\n",
    "\n",
    "def create_similarity_by_address(driver: Driver, jaro_threshold: float = 0.2) -> None:\n",
    "    \"\"\"Creates SIMILAR relationships based on address similarity.\"\"\"\n",
    "    query = f\"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "      \"MATCH (c:Candidate {{batchId:'{BATCH_ID}'}}) WHERE c.normalizedAddress IS NOT NULL RETURN c\",\n",
    "      \"MATCH (c2:Candidate {{batchId:'{BATCH_ID}'}}) \n",
    "       WHERE c2.normalizedAddress IS NOT NULL AND id(c) < id(c2)\n",
    "       WITH c, c2, apoc.text.jaroWinklerDistance(c.normalizedAddress, c2.normalizedAddress) AS dist\n",
    "       WHERE dist < {jaro_threshold}\n",
    "       CREATE (c)-[:SIMILAR {{\n",
    "         comparedProperty: 'address',\n",
    "         similarity: (1.0 - dist)\n",
    "       }}]->(c2)\",\n",
    "      {{batchSize:200, parallel:false}}\n",
    "    )\n",
    "    \"\"\"\n",
    "    with driver.session(database=DB_NAME) as session:\n",
    "        session.run(query)\n",
    "    logger.info(\"Created SIMILAR relationships by address.\")\n",
    "\n",
    "# Run these cells (one at a time or in a block) to create indexes, apply blocking, and generate SIMILAR relationships:\n",
    "driver_instance = get_driver()\n",
    "create_candidate_indexes(driver_instance)\n",
    "# Optionally: create_soundex_blocking(driver_instance)  # Uncomment if blocking is desired.\n",
    "create_similarity_by_name(driver_instance, jaro_threshold=0.15)\n",
    "create_similarity_by_email(driver_instance, similarity_threshold=0.9)\n",
    "create_similarity_by_phone(driver_instance, similarity_threshold=0.9)\n",
    "create_similarity_by_address(driver_instance, jaro_threshold=0.2)\n",
    "driver_instance.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Duplicate Resolution Functions\n",
    "\n",
    "Two strategies for handling duplicates are introduced in this section.\n",
    "\n",
    "merge_high_confidence merges candidate nodes that have an aggregated similarity score above a specified threshold, effectively combining duplicates (a destructive approach).\n",
    "link_high_confidence creates a :SAME_AS relationship between high-confidence duplicate nodes without merging them (a non-destructive approach).\n",
    "These functions help further refine the deduplication process based on the quality of the similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_high_confidence(driver: Driver, threshold: float = 2.5) -> None:\n",
    "    \"\"\"\n",
    "    Merge candidate nodes if their aggregated similarity (weightedSum) is \n",
    "    greater than or equal to the threshold. This is destructive.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    CALL apoc.periodic.iterate(\n",
    "      \"MATCH (c1:Candidate)-[r:AGGREGATED_SIMILAR]->(c2:Candidate)\n",
    "       WHERE r.weightedSum >= {threshold}\n",
    "       RETURN c1, c2\",\n",
    "      \"CALL apoc.refactor.mergeNodes([c1, c2], {{\n",
    "         properties: 'combine',\n",
    "         mergeRels: true\n",
    "      }}) YIELD node RETURN node\",\n",
    "      {{batchSize: 100, parallel: false}}\n",
    "    )\n",
    "    \"\"\"\n",
    "    with driver.session(database=DB_NAME) as session:\n",
    "        session.run(query)\n",
    "    logger.info(f\"Nodes merged where weightedSum >= {threshold}.\")\n",
    "\n",
    "def link_high_confidence(driver: Driver, threshold: float = 2.5) -> None:\n",
    "    \"\"\"\n",
    "    Create :SAME_AS relationships between candidate nodes if their aggregated \n",
    "    similarity (weightedSum) is greater than or equal to the threshold.\n",
    "    This is non-destructive.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    MATCH (c1:Candidate)-[r:AGGREGATED_SIMILAR]->(c2:Candidate)\n",
    "    WHERE r.weightedSum >= {threshold}\n",
    "    MERGE (c1)-[:SAME_AS {{confidence: r.weightedSum}}]->(c2)\n",
    "    \"\"\"\n",
    "    with driver.session(database=DB_NAME) as session:\n",
    "        session.run(query)\n",
    "    logger.info(f\"Linked nodes with :SAME_AS where weightedSum >= {threshold}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Linked nodes with :SAME_AS where weightedSum >= 2.5.\n"
     ]
    }
   ],
   "source": [
    "# Get a driver instance (or reuse your existing driver if still open)\n",
    "driver_instance = get_driver()\n",
    "\n",
    "# Choose one or both strategies:\n",
    "# Merge nodes (destructive):\n",
    "# merge_high_confidence(driver_instance, threshold=2.5)\n",
    "\n",
    "# Link nodes (non-destructive):\n",
    "link_high_confidence(driver_instance, threshold=2.5)\n",
    "\n",
    "driver_instance.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.  Master Entity Resolution Functions\n",
    "Description:\n",
    "\n",
    "This section focuses on deduplication by consolidating candidate nodes into master nodes. A master node is created for each unique community (determined by the clustering process), and candidate nodes are linked to their corresponding master node. Additionally, canonical properties are computed by aggregating values from the candidate nodes. This step results in a cleaned, deduplicated view of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: MasterEntity nodes created.\n",
      "INFO: Candidates linked to MasterEntity nodes.\n",
      "INFO: Canonical properties set for MasterEntity nodes.\n"
     ]
    }
   ],
   "source": [
    "def create_master_nodes_and_links() -> None:\n",
    "    \"\"\"\n",
    "    Creates distinct MasterEntity nodes for each candidate community (entityId) and links candidates to them.\n",
    "    \"\"\"\n",
    "    driver = get_driver()\n",
    "    with driver.session(database=DB_NAME) as session:\n",
    "        create_master_nodes_query = \"\"\"\n",
    "        CALL apoc.periodic.iterate(\n",
    "          \"MATCH (c:Candidate) WHERE c.entityId IS NOT NULL RETURN DISTINCT c.entityId AS communityId\",\n",
    "          \"MERGE (m:MasterEntity {communityId: communityId})\",\n",
    "          {batchSize: 1000, parallel: false}\n",
    "        )\n",
    "        \"\"\"\n",
    "        session.run(create_master_nodes_query)\n",
    "        logger.info(\"MasterEntity nodes created.\")\n",
    "        link_candidates_query = \"\"\"\n",
    "        CALL apoc.periodic.iterate(\n",
    "          \"MATCH (c:Candidate) WHERE c.entityId IS NOT NULL RETURN c\",\n",
    "          \"MATCH (m:MasterEntity {communityId: c.entityId}) MERGE (c)-[:BELONGS_TO]->(m)\",\n",
    "          {batchSize: 1000, parallel: false}\n",
    "        )\n",
    "        \"\"\"\n",
    "        session.run(link_candidates_query)\n",
    "        logger.info(\"Candidates linked to MasterEntity nodes.\")\n",
    "    driver.close()\n",
    "\n",
    "def set_canonical() -> None:\n",
    "    \"\"\"\n",
    "    Computes canonical property values for each MasterEntity from its related Candidate nodes.\n",
    "    \"\"\"\n",
    "    driver = get_driver()\n",
    "    with driver.session(database=DB_NAME) as session:\n",
    "        query = \"\"\"\n",
    "        CALL apoc.periodic.iterate(\n",
    "          'MATCH (m:MasterEntity) RETURN m',\n",
    "          'MATCH (c:Candidate {entityId: m.communityId})\n",
    "           WITH m, \n",
    "                collect(c.fullName) AS allNames, \n",
    "                collect(c.email) AS allEmails, \n",
    "                collect(c.phoneNumber) AS allPhones, \n",
    "                collect(c.address) AS allAddresses\n",
    "           WITH m,\n",
    "                apoc.coll.frequenciesAsMap(allNames) AS nameFreq,\n",
    "                apoc.coll.frequenciesAsMap(allEmails) AS emailFreq,\n",
    "                apoc.coll.frequenciesAsMap(allPhones) AS phoneFreq,\n",
    "                apoc.coll.frequenciesAsMap(allAddresses) AS addrFreq\n",
    "           WITH m,\n",
    "                keys(nameFreq)[0] AS bestName,\n",
    "                keys(emailFreq)[0] AS bestEmail,\n",
    "                keys(phoneFreq)[0] AS bestPhone,\n",
    "                keys(addrFreq)[0] AS bestAddress\n",
    "           SET m.fullNameCanonical = bestName,\n",
    "               m.emailCanonical = bestEmail,\n",
    "               m.phoneNumberCanonical = bestPhone,\n",
    "               m.addressCanonical = bestAddress',\n",
    "          {batchSize:50, parallel:false}\n",
    "        )\n",
    "        \"\"\"\n",
    "        session.run(query)\n",
    "        logger.info(\"Canonical properties set for MasterEntity nodes.\")\n",
    "    driver.close()\n",
    "\n",
    "# Run these cells to create master entities and set canonical properties:\n",
    "create_master_nodes_and_links()\n",
    "set_canonical()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
